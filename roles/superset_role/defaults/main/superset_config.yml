---

# superset_config.py

superset_stats_logger:
superset_event_logger:
superset_log_view: True

superset_base_dir:
superset_data_dir:

# default viz used in chart explorer
superset_default_viz_type: table
superset_row_limit: 50000
superset_viz_row_limit: 10000
# max rows retreieved when requesting samples from datasource in explore view
superset_samples_row_limit: 1000
# max rows retrieved by filter select auto complete
superset_filter_select_row_limit: 10000

# Webserver
superset_webserver_protocol: http
superset_webserver_address: 0.0.0.0
superset_webserver_port: 8088

# This is an important setting, and should be lower than your
# [load balancer / proxy / envoy / kong / ...] timeout settings.
# You should also make sure to configure your WSGI server
# (gunicorn, nginx, apache, ...) timeout setting to be <= to this setting
superset_webserver_timeout: 60

# this 2 settings are used by dashboard period force refresh feature
# When user choose auto force refresh frequency
# < SUPERSET_DASHBOARD_PERIODICAL_REFRESH_LIMIT
# they will see warning message in the Refresh Interval Modal.
# please check PR #9886
superset_dashboard_periodical_refresh_limit: 0
superset_dashboard_periodical_refresh_warning_message: None

superset_dashboard_position_data_limit: 65535
superset_custom_security_manager: None
superset_sqlalchemy_track_modifications: False

superset_secret_key: \2\1thisismyscretkey\1\2\\e\\y\\y\\h
superset_sqlalchemy_database_uri: "sqlite:///{{ superset_metadatadb_path }}/superset.db"

# In order to hook up a custom password store for all SQLACHEMY connections
# implement a function that takes a single argument of type 'sqla.engine.url',
# returns a password and set SQLALCHEMY_CUSTOM_PASSWORD_STORE.
#
# e.g.:
# def lookup_password(url):
#     return 'secret'
# SQLALCHEMY_CUSTOM_PASSWORD_STORE = lookup_password
superset_sqlalchemy_custom_password_store: None

# The EncryptedFieldTypeAdapter is used whenever we're building SqlAlchemy models
# which include sensitive fields that should be app-encrypted BEFORE sending
# to the DB.
#
# Note: the default impl leverages SqlAlchemyUtils' EncryptedType, which defaults
#  to AES-128 under the covers using the app's SECRET_KEY as key material.
#
# pylint: disable=C0103
superset_sqlalchemy_encrypted_field_type_adapter:

# The limit of queries fetched for query search
superset_query_search_limit: 1000

# Flask-WTF flag for CSRF
superset_wtf_csrf_enabled: True

# Add endpoints that need to be exempt from CSRF protection
superset_wtf_csrf_exempt_list: ["superset.views.core.log", "superset.charts.api.data"]

# Whether to run the web server in debug mode or not
superset_debug: False
superset_flask_use_reload: True

# Superset allows server-side python stacktraces to be surfaced to the
# user when this feature is on. This may has security implications
# and it's more secure to turn it off in production settings.
superset_show_stacktrace: True

# Use all X-Forwarded headers when ENABLE_PROXY_FIX is True.
# When proxying to a different port, set "x_port" to 0 to avoid downstream issues.
superset_enable_proxy_fix: False
superset_proxy_fix_config: {"x_for": 1, "x_proto": 1, "x_host": 1, "x_port": 1, "x_prefix": 1}

# ------------------------------
# GLOBALS FOR APP Builder
# ------------------------------
superset_app_name: superset
superset_app_icon: /static/assets/images/superset-logo-horiz.png
superset_app_icon_width: 126

# To specify where clicking the logo would take the user
# e.g. setting it to '/' would take the user to '/superset/welcome/'
superset_logo_target_path: None

# Enables SWAGGER UI for superset openapi spec
# ex: http://localhost:8080/swagger/v1
superset_fab_api_swagger_ui: True

# Druid query timezone
# tz.tzutc() : Using utc timezone
# tz.tzlocal() : Using local timezone
# tz.gettz('Asia/Shanghai') : Using the time zone with specific name
# [TimeZone List]
# See: https://en.wikipedia.org/wiki/List_of_tz_database_time_zones
# other tz can be overridden by providing a local_config
superset_druid_tz: tz.tzutc()
superset_druid_analysis_types: ["cardinality"]

# Legacy Druid NoSQL (native) connector
# Druid supports a SQL interface in its newer versions.
# Setting this flag to True enables the deprecated, API-based Druid
# connector. This feature may be removed at a future date.
superset_druid_is_active: False

# If Druid is active whether to include the links to scan/refresh Druid datasources.
# This should be disabled if you are trying to wean yourself off of the Druid NoSQL
# connector.
superset_druid_metadata_links_enabled: True

# [Authentication]
# The authentication type
# AUTH_OID : Is for OpenID
# AUTH_DB : Is for database (username/password)
# AUTH_LDAP : Is for LDAP
# AUTH_REMOTE_USER : Is for using REMOTE_USER from web server
superset_auth_type: AUTH_DB

# To setup Full admin role name
superset_auth_role_admin: Admin

# To setup Public role name, no authentication needed
superset_auth_role_public: Public

# Will allow user self registration (True/False)
superset_auth_user_registration: False

# The default user self registration role
superset_auth_user_registration_role: Public

# [LDAP]
# When using LDAP Auth, setup the LDAP server
superset_auth_ldap_server: ldap://ldapserver.new
superset_auth_ldap_use_tls: False
superset_auth_ldap_tls_demand: False  # Demands TLS peer certificate checking (Bool)
superset_auth_ldap_tls_cacertdir:  # CA Certificate directory to check peer certificate
superset_auth_ldap_tls_cacertfile:  # CA Certificate file to check peer certificate
superset_auth_ldap_tls_certfile:  # Certificate file for client auth use with AUTH_LDAP_TLS_KEYFILE
superset_auth_ldap_tls_keyfile:  # Certificate key file for client aut
superset_auth_ldap_allow_self_signed:  # Allow LDAP authentication to use self signed certificates (LDAPS)
superset_auth_ldap_firstname_field: givenName
superset_auth_ldap_lastname_field: sn
superset_auth_ldap_email_field: mail
superset_auth_ldap_search:  # the LDAP search base
superset_auth_ldap_append_domain:  # The append domain
superset_auth_ldap_uid_field:  # the username field
superset_auth_ldap_bind_user:  # the special bind username for search
superset_auth_ldap_bind_password:  # the special bind password for search
superset_auth_ldap_username_format:  # It converts username to specific format for LDAP authentications.
superset_auth_ldap_search_filter:  # limit the LDAP search scope
superset_auth_roles_mapping: {}  # a mapping from LDAP DN to a list of FAB roles
superset_auth_ldap_group_field:  # the LDAP user attribute which has their role DNs
superset_auth_roles_sync_at_login: True  # if we should replace ALL the user's roles each login, or only on registration
superset_permanent_session_lifetime: 1800  # force users to re-auth after 30min of inactivity (to keep roles in sync)

# To setup OpenID providers example for OpenID authentication
# superset_openid_providers: [
#   { 'name': 'Yahoo', 'url': 'https://open.login.yahoo.com/' },
#   { 'name': 'Flickr', 'url': 'https://www.flickr.com/<username>' },
# ]
superset_openid_providers: []

# [Roles config]
# Grant public role the same set of permissions as for a selected builtin role.
# This is useful if one wants to enable anonymous users to view
# dashboards. Explicit grant on specific datasets is still required.
superset_public_role_like: None

# [Babel config for translations]
# Setup default language
superset_babel_default_locale: en

# Your application default translation path
superset_babel_default_folder: = superset/translations

# The allowed translation for you app
superset_languages: {
  "en": {"flag": "us", "name": "English"},
  "es": {"flag": "es", "name": "Spanish"},
  "it": {"flag": "it", "name": "Italian"},
  "fr": {"flag": "fr", "name": "French"},
  "zh": {"flag": "cn", "name": "Chinese"},
  "ja": {"flag": "jp", "name": "Japanese"},
  "de": {"flag": "de", "name": "German"},
  "pt": {"flag": "pt", "name": "Portuguese"},
  "pt_BR": {"flag": "br", "name": "Brazilian Portuguese"},
  "ru": {"flag": "ru", "name": "Russian"},
  "ko": {"flag": "kr", "name": "Korean"},
}

# [FEATURE_FLAGS]

# allow dashboard to use sub-domains to send chart request
# you also need ENABLE_CORS and
# SUPERSET_WEBSERVER_DOMAINS for list of domains
superset_allow_dashboard_domain_sharding: True

# Experimental feature introducing a client (browser) cache
superset_client_cache: False
superset_disable_dataset_source_edit: False
superset_dynamic_plugins: False

# For some security concerns, you may need to enforce CSRF protection on
# all query request to explore_json endpoint. In Superset, we use
# `flask-csrf <https://sjl.bitbucket.io/flask-csrf/>`_ add csrf protection
# for all POST requests, but this protection doesn't apply to GET method.
# When ENABLE_EXPLORE_JSON_CSRF_PROTECTION is set to true, your users cannot
# make GET request to explore_json. explore_json accepts both GET and POST request.
# See `PR 7935 <https://github.com/apache/superset/pull/7935>`_ for more details.
superset_enable_explore_json_csrf_protection: False
superset_enable_template_processing: False
superset_kv_store: False

# When this feature is enabled, nested types in Presto will be
# expanded into extra columns and/or arrays. This is experimental,
# and doesn't work with all nested types.
superset_presto_expand_data: False

# Exposes API endpoint to compute thumbnails
superset_thumbnails: False
superset_dashboard_cache: False
superset_remove_slice_level_label_colors: False
superset_share_queries_via_kv_store: False
superset_tagging_system: False
superset_sqllab_backend_persistence: False
superset_listviews_default_card_view: False

# Enables the replacement React views for all the FAB views (list, edit, show) with
# designs introduced in https://github.com/apache/superset/issues/8976
# (SIP-34). This is a work in progress so not all features available in FAB have
# been implemented.
superset_enable_react_crud_views: True

# When True, this flag allows display of HTML tags in Markdown components
superset_display_markdown_html: True

# When True, this escapes HTML (rather than rendering it) in Markdown components
superset_escape_markdown_html: False
superset_dashboard_native_filters: False
superset_dashboard_cross_filters: False
superset_dashboard_native_filters_set: False
superset_global_async_queries: False
superset_versioned_export: False

# Note that: RowLevelSecurityFilter is only given by default to the Admin role
# and the Admin Role does have the all_datasources security permission.
# But, if users create a specific role with access to RowLevelSecurityFilter MVC
# and a custom datasource access, the table dropdown will not be correctly filtered
# by that custom datasource access. So we are assuming a default security config,
# a custom security config could potentially give access to setting filters on
# tables that users do not have access to.
superset_row_level_security: True

# Enables Alerts and reports new implementation
superset_alert_reports: False

# Enable experimental feature to search for other dashboards
superset_omnibar: False

superset_dashboard_rbac: False
superset_enable_explore_drag_and_drop: False

# Enabling ALERTS_ATTACH_REPORTS, the system sends email and slack message
# with screenshot and link
# Disables ALERTS_ATTACH_REPORTS, the system DOES NOT generate screenshot
# for report with type 'alert' and sends email and slack message with only link;
# for report with type 'report' still send with email and slack message with
# screenshot and link
superset_alerts_attach_reports: True

# Enabling FORCE_DATABASE_CONNECTIONS_SSL forces all database connections to be
# encrypted before being saved into superset metastore.
superset_force_database_connections_ssl: False

# Optional user added vars to FEATURE FLAGS
# superset_feature_flags_extra:
#   - name: TEST
#     value: False

#   - name: FOO
#     value: "\"bar\""

# [END FEATURE_FLAGS]

# [ Color schemes ]
# EXTRA_CATEGORICAL_COLOR_SCHEMES is used for adding custom categorical color schemes
# example code for "My custom warm to hot" color scheme
# superset_extra_categorical_color_schemes: [
#   {
#     "id": 'myVisualizationColors',
#     "description": '',
#     "label": 'My Visualization Colors',
#     "colors":
#       ['#006699', '#009DD9', '#5AAA46', '#44AAAA', '#DDAA77', '#7799BB', '#88AA77',
#       '#552288', '#5AAA46', '#CC7788', '#EEDD55', '#9977BB', '#BBAA44', '#DDCCDD']
#   }]
superset_extra_categorical_color_schemes:

# THEME_OVERRIDES is used for adding custom theme to superset
# example code for "My theme" custom scheme
# superset_theme_overrides: {
#   "borderRadius": 4,
#   "colors": {
#     "primary": {
#       "base": 'red',
#     },
#     "secondary": {
#       "base": 'green',
#     },
#     "grayscale": {
#       "base": 'orange',
#     }
#   }
# }
superset_theme_overrides:

# EXTRA_SEQUENTIAL_COLOR_SCHEMES is used for adding custom sequential color schemes
# superset_extra_sequential_color_schemes: [{
#   "id": 'warmToHot',
#   "description": '',
#   "isDiverging": True,
#   "label": 'My custom warm to hot',
#   "colors":
#     ['#552288', '#5AAA46', '#CC7788', '#EEDD55', '#9977BB', '#BBAA44', '#DDCCDD',
#     '#006699', '#009DD9', '#5AAA46', '#44AAAA', '#DDAA77', '#7799BB', '#88AA77']
# }]
superset_extra_sequential_color_schemes:

superset_thumbnail_selenium_user: admin
superset_thumbnail_cache_config: {
  "CACHE_TYPE": "null",
  "CACHE_NO_NULL_WARNING": True,
}

# Used for thumbnails and other api: Time in seconds before selenium
# times out after trying to locate an element on the page and wait
# for that element to load for an alert screenshot.
superset_screenshot_locate_wait: 10
superset_screenshot_load_wait: 60

# [ Image and file conf ]
# The file upload folder, when using models with files
superset_upload_folder: "/srv/{{ superset_app_name }}/upload"
superset_upload_chunk_size: 4096

# The image upload folder, when using models with images
superset_img_upload_folder: "{{ superset_upload_folder }}/img"

# The image upload url, when using models with images
superset_img_upload_url: /static/uploads/
# Setup image size default is (300, 200, True)
superset_img_size:

# Default cache timeout (in seconds), applies to all cache backends unless
# specifically overridden in each cache config.
superset_cache_default_timeout: 60 * 60 * 24  # 1 day

# Default cache for Superset objects
superset_cache_config: {"CACHE_TYPE": "null"}

# Cache for datasource metadata and query results
superset_data_cache_config: {"CACHE_TYPE": "null"}

# store cache keys by datasource UID (via CacheKey) for custom processing/invalidation
superset_store_cache_keys_in_metadata_db: False

# CORS Options
superset_enable_cors: False
superset_cors_options: {}

# Chrome allows up to 6 open connections per domain at a time. When there are more
# than 6 slices in dashboard, a lot of time fetch requests are queued up and wait for
# next available socket. PR #5039 is trying to allow domain sharding for Superset,
# and this feature will be enabled by configuration only (by default Superset
# doesn't allow cross-domain request).
superset_webserver_domains: None

# Allowed format types for upload on Database view
superset_excel_extensions: '{"xlsx", "xls"}'
superset_csv_extensions: '{"csv", "tsv", "txt"}'
superset_allowed_extensions: "{*EXCEL_EXTENSIONS, *CSV_EXTENSIONS}"

# CSV Options: key/value pairs that will be passed as argument to DataFrame.to_csv
# method.
# note: index option should not be overridden
superset_csv_export: {"encoding": "utf-8"}

# [ Time grain configurations ]
# List of time grains to disable in the application (see list of builtin
# time grains in superset/db_engine_specs.builtin_time_grains).
# For example: to disable 1 second time grain:
# TIME_GRAIN_DENYLIST = ['PT1S']
superset_time_grain_denylist: []

# Additional time grains to be supported using similar definitions as in
# superset/db_engine_specs.builtin_time_grains.
# For example: To add a new 2 second time grain:
# TIME_GRAIN_ADDONS = {'PT2S': '2 second'}
superset_time_grain_addons: {}

# Implementation of additional time grains per engine.
# The column to be truncated is denoted `{col}` in the expression.
# For example: To implement 2 second time grain on clickhouse engine:
# TIME_GRAIN_ADDON_EXPRESSIONS = {
#     'clickhouse': {
#         'PT2S': 'toDateTime(intDiv(toUInt32(toDateTime({col})), 2)*2)'
#     }
# }
superset_time_grain_addon_expressions: {}

# List of viz_types not allowed in your environment
# For example: Disable pivot table and treemap:
#  VIZ_TYPE_DENYLIST = ['pivot_table', 'treemap']
superset_viz_type_denylist: []

# Modules, datasources and middleware to be registered
superset_default_module_ds_map:
superset_additional_module_ds_map: {}
superset_additional_middleware: []

# Default configurator will consume the LOG_* settings below
superset_logging_configurator:

# Console Log Settings
superset_log_format: "%(asctime)s:%(levelname)s:%(name)s:%(message)s"

superset_log_level: DEBUG  # DEBUG, INFO, WARNING, ERROR, CRITICAL

superset_enable_time_rotate: False
superset_time_rotate_log_level: DEBUG
superset_log_filename: "{{ superset_log_path }}/superset.log"
superset_rollover: midnight
superset_interval: 1
superset_backup_count: 30

# Custom logger for auditing queries. This can be used to send ran queries to a
# structured immutable store for auditing purposes. The function is called for
# every query ran, in both SQL Lab and charts/dashboards.
superset_query_logger: None

# Set this API key to enable Mapbox visualizations
superset_mapbox_api_key:

# Maximum number of rows returned from a database
# in async mode, no more than SQL_MAX_ROW will be returned and stored
# in the results backend. This also becomes the limit when exporting CSVs
superset_sql_max_row: 100000

# Maximum number of rows displayed in SQL Lab UI
# Is set to avoid out of memory/localstorage issues in browsers. Does not affect
# exported CSVs
superset_display_max_row: 10000

# Default row limit for SQL Lab queries. Is overridden by setting a new limit in
# the SQL Lab UI
superset_default_sqllab_limit: 10000

# Maximum number of tables/views displayed in the dropdown window in SQL Lab.
superset_max_table_names: 3000

# Adds a warning message on sqllab save query and schedule query modals.
superset_sqllab_save_warning_message: None
superset_sqllab_schedule_warning_message: None

# [ Celery config ]
superset_celery_flower_port: 5555
superset_broker_url: sqla+sqlite:///celerydb.sqlite
superset_celery_imports: ("superset.sql_lab", "superset.tasks")
superset_celery_result_backend: db+sqlite:///celery_results.sqlite
superset_celeryd_log_level: DEBUG
superset_celeryd_prefetch_multiplier: 1
superset_celery_acks_late: False
superset_celery_annotations:
  "{
    'sql_lab.get_sql_results': {'rate_limit': '100/s'},
    'email_reports.send': {
      'rate_limit': '1/s',
      'time_limit': 120,
      'soft_time_limit': 150,
      'ignore_result': True,
    },
  }"
superset_celerybeat_schedule:
  "{
    'email_reports.schedule_hourly': {
      'task': 'email_reports.schedule_hourly',
      'schedule': crontab(minute=1, hour='*'),
    },
    'reports.scheduler': {
      'task': 'reports.scheduler',
      'schedule': crontab(minute='*', hour='*'),
    },
    'reports.prune_log': {
      'task': 'reports.prune_log',
      'schedule': crontab(minute=0, hour=0),
    },
  }"

# Set celery config to None to disable all the above configuration
superset_celery_config: CeleryConfig

# Additional static HTTP headers to be served by your Superset server. Note
# Flask-Talisman applies the relevant security HTTP headers.
#
# DEFAULT_HTTP_HEADERS: sets default values for HTTP headers. These may be overridden
# within the app
# OVERRIDE_HTTP_HEADERS: sets override values for HTTP headers. These values will
# override anything set within the app
superset_default_http_headers: {}
superset_override_http_headers: {}
superset_http_headers: {}

# The db id here results in selecting this one as a default in SQL Lab
superset_default_db_id: None

# Timeout duration for SQL Lab synchronous queries
superset_sqllab_timeout: 30

# Timeout duration for SQL Lab query validation
superset_sqllab_validation_timeout: 10

# SQLLAB_DEFAULT_DBID
superset_sqllab_default_dbid: None

# The MAX duration (in seconds) a query can run for before being killed
# by celery.
superset_sqllab_async_time_limit_sec: 60 * 60 * 6

# Some databases support running EXPLAIN queries that allow users to estimate
# query costs before they run. These EXPLAIN queries should have a small
# timeout.
superset_sqllab_query_cost_estimate_timeout: 10  # seconds
# The feature is off by default, and currently only supported in Presto and Postgres.
# It also need to be enabled on a per-database basis, by adding the key/value pair
# `cost_estimate_enabled: true` to the database `extra` attribute.
superset_estimate_query_cost: False
# The cost returned by the databases is a relative value; in order to map the cost to
# a tangible value you need to define a custom formatter that takes into consideration
# your specific infrastructure. For example, you could analyze queries a posteriori by
# running EXPLAIN on them, and compute a histogram of relative costs to present the
# cost as a percentile:
#
# def postgres_query_cost_formatter(
#     result: List[Dict[str, Any]]
# ) -> List[Dict[str, str]]:
#     # 25, 50, 75% percentiles
#     percentile_costs = [100.0, 1000.0, 10000.0]
#
#     out = []
#     for row in result:
#         relative_cost = row["Total cost"]
#         percentile = bisect.bisect_left(percentile_costs, relative_cost) + 1
#         out.append({
#             "Relative cost": relative_cost,
#             "Percentile": str(percentile * 25) + "%",
#         })
#
#     return out
#
# FEATURE_FLAGS = {
#     "ESTIMATE_QUERY_COST": True,
#     "QUERY_COST_FORMATTERS_BY_ENGINE": {"postgresql": postgres_query_cost_formatter},
# }
superset_query_cost_formatters_by_engine: {"postgresql": postgres_query_cost_formatter}

# Flag that controls if limit should be enforced on the CTA (create table as queries).
superset_sqllab_ctas_no_limit: False

superset_sqllab_ctas_schema_name_func: None

# If enabled, it can be used to store the results of long-running queries
# in SQL Lab by using the "Run Async" button/feature
superset_results_backend: None

# Use PyArrow and MessagePack for async query results serialization,
# rather than JSON. This feature requires additional testing from the
# community before it is fully adopted, so this config option is provided
# in order to disable should breaking issues be discovered.
superset_results_backend_use_msgpack: True

# The S3 bucket where you want to store your external hive tables created
# from CSV files. For example, 'companyname-superset'
superset_csv_to_hive_upload_s3_bucket: None

# The directory within the bucket specified above that will
# contain all the external tables
superset_csv_to_hive_upload_directory: EXTERNAL_HIVE_TABLES/

# The namespace within hive where the tables created from
# uploading CSVs will be stored.
superset_uploaded_csv_hive_namespace: None

# Values that should be treated as nulls for the csv uploads.
superset_csv_default_na_names:

# A dictionary of items that gets merged into the Jinja context for
# SQL Lab. The existing context gets updated with this dictionary,
# meaning values for existing keys get overwritten by the content of this
# dictionary. Exposing functionality through JINJA_CONTEXT_ADDONS has security
# implications as it opens a window for a user to execute untrusted code.
# It's important to make sure that the objects exposed (as well as objects attached
# to those objets) are harmless. We recommend only exposing simple/pure functions that
# return native types.
superset_jinja_context_addons: {}

# A dictionary of macro template processors (by engine) that gets merged into global
# template processors. The existing template processors get updated with this
# dictionary, which means the existing keys get overwritten by the content of this
# dictionary. The customized addons don't necessarily need to use Jinja templating
# language. This allows you to define custom logic to process templates on a per-engine
# basis. Example value = `{"presto": CustomPrestoTemplateProcessor}`
superset_custom_template_processors: {}

# Roles that are controlled by the API / Superset and should not be changes
# by humans.
superset_robot_permission_roles: ["Public", "Gamma", "Alpha", "Admin", "sql_lab"]

superset_config_path_env_var: SUPERSET_CONFIG_PATH

# If a callable is specified, it will be called at app startup while passing
# a reference to the Flask app. This can be used to alter the Flask app
# in whatever way.
# example: FLASK_APP_MUTATOR = lambda x: x.before_request = f
superset_flask_app_mutator: None

# Set this to false if you don't want users to be able to request/grant
# datasource access requests from/to other users.
superset_enable_access_request: False

# [ SMTP smtp server configuration ]
superset_email_notifications: False  # all the emails are sent using dryrun
superset_smtp_host: "localhost"
superset_smtp_starttls: True
superset_smtp_ssl: False
superset_smtp_user:
superset_smtp_password:
superset_smtp_port: 25
superset_smtp_mail_from:

superset_enable_chunk_encoding: False

# Whether to bump the logging level to ERROR on the flask_appbuilder package
# Set to False if/when debugging FAB related issues like
# permission management
superset_silence_fab: True

superset_fab_add_security_views: True
superset_fab_add_security_permission_view: True
superset_fab_add_security_view_menu_view: True
superset_fab_add_security_permission_views_view: True

# The link to a page containing common errors and their resolutions
# It will be appended at the bottom of sql_lab errors.
superset_troubleshooting_link: ""

# CSRF token timeout, set to None for a token that never expires
superset_wtf_csrf_time_limit: 60 * 60 * 24 * 7

# This link should lead to a page with instructions on how to gain access to a
# Datasource. It will be placed at the bottom of permissions errors.
superset_permission_instructions_link: ""

# Integrate external Blueprints to the app by passing them to your
# configuration. These blueprints will get integrated in the app
superset_blueprints: []

# Provide a callable that receives a tracking_url and returns another
# URL. This is used to translate internal Hadoop job tracker URL
# into a proxied one
superset_tracking_url_transformer: "lambda x: x"

# Interval between consecutive polls when using Hive Engine
superset_hive_poll_interval: 5

# Interval between consecutive polls when using Presto Engine
# See here: https://github.com/dropbox/PyHive/blob/8eb0aeab8ca300f3024655419b93dad926c1a351/pyhive/presto.py#L93  # pylint: disable=line-too-long
superset_presto_poll_interval: 1

# Allow for javascript controls components
# this enables programmers to customize certain charts (like the
# geospatial ones) by inputing javascript in controls. This exposes
# an XSS security vulnerability
superset_enable_javascript_controls: False

# The id of a template dashboard that should be copied to every new user
superset_dashboard_template_id: None

# A callable that allows altering the database connection URL and params
# on the fly, at runtime. This allows for things like impersonation or
# arbitrary logic. For instance you can wire different users to
# use different connection parameters, or pass their email address as the
# username. The function receives the connection uri object, connection
# params, the username, and returns the mutated uri and params objects.
# Note that the returned uri and params are passed directly to sqlalchemy's
# as such `create_engine(url, **params)`
superset_db_connection_mutator: None

# A function that intercepts the SQL to be executed and can alter it.
# The use case is can be around adding some sort of comment header
# with information such as the username and worker node information
supserset_sql_query_mutator: None

# [ Alerts & Reports]
# Used for Alerts/Reports (Feature flask ALERT_REPORTS) to set the size for the
# sliding cron window size, should be synced with the celery beat config minus 1 second
superset_alert_reports_cron_window_size: 59
superset_alert_reports_working_time_out_kill: True

# if ALERT_REPORTS_WORKING_TIME_OUT_KILL is True, set a celery hard timeout
# Equal to working timeout + ALERT_REPORTS_WORKING_TIME_OUT_LAG
superset_alert_reports_working_time_out_lag: 10

# if ALERT_REPORTS_WORKING_TIME_OUT_KILL is True, set a celery hard timeout
# Equal to working timeout + ALERT_REPORTS_WORKING_SOFT_TIME_OUT_LAG
superset_alert_reports_working_soft_time_out_lag: 1

# If set to true no notification is sent, the worker will just log a message.
# Useful for debugging
superset_alert_reports_notification_dry_run: False

# A custom prefix to use on all Alerts & Reports emails
superset_email_reports_subject_prefix: "[Report] "

# Slack API token for the superset reports, either string or callable
superset_slack_api_token: None
superset_slack_proxy: None

# This auth provider is used by background (offline) tasks that need to access
# protected resources. Can be overridden by end users in order to support
# custom auth mechanisms
superset_machine_auth_provider_class: "superset.utils.machine_auth.MachineAuthProvider"

# [ Webdriver ]
# The webdriver to use for generating reports. Use one of the following
# firefox
#   Requires: geckodriver and firefox installations
#   Limitations: can be buggy at times
# chrome:
#   Requires: headless chrome
#   Limitations: unable to generate screenshots of elements
superset_webdriver_type: chrome

# Window size - this will impact the rendering of the data
superset_webdriver_window: "{'dashboard': (1600, 2000), 'slice': (3000, 1200)}"

# An optional override to the default auth hook used to provide auth to the
# offline webdriver
superset_webdriver_auth_func: None

# Any config options to be passed as-is to the webdriver
superset_webdriver_configuration: '{"service_log_path": "/dev/null"}'

# Additional args to be passed as arguments to the config object
# Note: these options are Chrome-specific. For FF, these should
# only include the "--headless" arg
# Chrome
superset_webdriver_option_args: [
  "--headless",
  "--no-sandbox",
  "--marionette",
  "--force-device-scale-factor=2.0",
  "--high-dpi-support=2.0",
  "--disable-gpu",
  "--disable-dev-shm-usage",
  "--disable-setuid-sandbox",
  "--disable-extensions",
]
# Firefox
# superset_webdriver_option_args: [
#   "--headless",
# ]

# The base URL to query for accessing the user interface
superset_webdriver_baseurl: "http://{{ superset_webserver_address }}:{{ superset_webserver_port }}/"
# The base URL for the email report hyperlinks.
superset_webdriver_baseurl_user_friendly: "{{ superset_webdriver_baseurl }}"
# Time in seconds, selenium will wait for the page to load
# and render for the email report.
superset_email_page_render_wait: 30

# Send user to a link where they can report bugs
superset_bug_report_url: None

# Send user to a link where they can read more about Superset
superset_documentation_url: None
superset_documentation_text: Documentation
superset_documentation_icon: None  # Recommended size: 16x16

# What is the Last N days relative in the time selector to:
# 'today' means it is midnight (00:00:00) in the local timezone
# 'now' means it is relative to the query issue time
# If both start and end time is set to now, this will make the time
# filter a moving window. By only setting the end time to now,
# start time will be set to midnight, while end will be relative to
# the query issue time.
superset_default_relative_start_time: today
superset_default_relative_end_time: today

# Configure which SQL validator to use for each engine
superset_sql_validators_by_engine: {
  "presto": "PrestoDBSQLValidator",
  "postgresql": "PostgreSQLValidator",
}

# A list of preferred databases, in order. These databases will be
# displayed prominently in the "Add Database" dialog. You should
# use the "engine" attribute of the corresponding DB engine spec in
# `superset/db_engine_specs/`.
superset_preferred_databases: []

# Do you want Talisman enabled?
superset_talisman_enabled: False
# If you want Talisman, how do you want it configured??
superset_talisman_config: {
  "content_security_policy": None,
  "force_https": True,
  "force_https_permanent": False,
}

# It is possible to customize which tables and roles are featured in the RLS
# dropdown. When set, this dict is assigned to `add_form_query_rel_fields` and
# `edit_form_query_rel_fields` on `RowLevelSecurityFiltersModelView`. Example:
# from flask_appbuilder.models.sqla import filters
# RLS_FORM_QUERY_REL_FIELDS = {
#     "roles": [["name", filters.FilterStartsWith, "RlsRole"]]
#     "tables": [["table_name", filters.FilterContains, "rls"]]
# }
superset_rls_form_query_rel_fields: None

# [ Flask session cookie options ]
# See https://flask.palletsprojects.com/en/1.1.x/security/#set-cookie-options for details
superset_session_cookie_httponly: True  # Prevent cookie from being read by frontend JS?
superset_session_cookie_secure: False  # Prevent cookie from being transmitted over non-tls?
superset_session_cookie_samesite: "Lax"  # One of [None, 'None', 'Lax', 'Strict']

# Flask configuration variables
superset_send_file_max_age_default: 60 * 60 * 24 * 365  # Cache static resources

# URI to database storing the example data, points to
# SQLALCHEMY_DATABASE_URI by default if set to `None`
superset_sqlalchemy_examples_uri: None

# Some sqlalchemy connection strings can open Superset to security risks.
# Typically these should not be allowed.
superset_prevent_unsafe_db_connections: True

# Path used to store SSL certificates that are generated when using custom certs.
# Defaults to temporary directory.
# Example: SSL_CERT_PATH = "/certs"
superset_ssl_cert_path: None

# SIP-15 should be enabled for all new Superset deployments which ensures that the time
# range endpoints adhere to [start, end). For existing deployments admins should provide
# a dedicated period of time to allow chart producers to update their charts before
# mass migrating all charts to use the [start, end) interval.
#
# Note if no end date for the grace period is specified then the grace period is
# indefinite.
superset_sip_15_enabled: True
superset_sip_15_grace_period_end: None  # exclusive
superset_sip_15_default_time_range_endpoints: ["unknown", "inclusive"]
superset_sip_15_toast_message: >
  'Action Required: Preview then save your chart using the new time range endpoints <a target="_blank" href="{url}" class="alert-link">here</a>.'

# SQLA table mutator, every time we fetch the metadata for a certain table
# (superset.connectors.sqla.models.SqlaTable), we call this hook
# to allow mutating the object with this callback.
# This can be used to set any properties of the object based on naming
# conventions and such. You can find examples in the tests.
superset_sqla_table_mutator: "lambda table: table"

# Global async query config options.
# Requires GLOBAL_ASYNC_QUERIES feature flag to be enabled.
superset_global_async_queries_redis_config: {
  "port": 6379,
  "host": "127.0.0.1",
  "password": "",
  "db": 0,
  "ssl": False,
}
superset_global_async_queries_redis_stream_prefix: async-events-
superset_global_async_queries_redis_stream_limit: 1000
superset_global_async_queries_redis_stream_limit_firehose: 1000000
superset_global_async_queries_jwt_cookie_name: async-token
superset_global_async_queries_jwt_cookie_secure: False
superset_global_async_queries_jwt_cookie_domain: None
superset_global_async_queries_jwt_secret: test-secret-change-me
superset_global_async_queries_transport: polling
superset_global_async_queries_polling_delay: 500
superset_global_async_queries_websocket_url: ws://127.0.0.1:8080/

# A SQL dataset health check. Note if enabled it is strongly advised that the callable
# be memoized to aid with performance, see template example
superset_dataset_health_check: None

# SQLalchemy link doc reference
superset_sqlalchemy_docs_url: https://docs.sqlalchemy.org/en/13/core/engines.html
superset_sqlalchemy_display_text: SQLAlchemy docs
